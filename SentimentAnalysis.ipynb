{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f72586eb-2dbd-4c4c-9398-8981d550e719",
      "metadata": {
        "id": "f72586eb-2dbd-4c4c-9398-8981d550e719",
        "outputId": "608d3d32-41c7-4b0a-978c-8d3a8616e136",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'sentimentAnalysis' already exists and is not an empty directory.\n",
            "/content/sentimentAnalysis\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Mateusz-Wojciechowski/sentimentAnalysis.git\n",
        "%cd sentimentAnalysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'portalocker>=2.0.0'"
      ],
      "metadata": {
        "id": "cwTXPiescQs2",
        "outputId": "d0495929-ae19-4add-9a9f-ba3455a5e70f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cwTXPiescQs2",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: portalocker>=2.0.0 in /usr/local/lib/python3.10/dist-packages (2.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "e-LLeI8xkcfD",
        "outputId": "7d1a87df-f8c1-4575-9a07-407dc04427d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "e-LLeI8xkcfD",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as fun\n",
        "from EncoderBlock import EncoderBlock\n",
        "from PositionalEncoding import PositionalEncoding\n",
        "\n",
        "\n",
        "class SentimentModel(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, num_heads, max_seq_len, num_classes, vocab_size):\n",
        "        super(SentimentModel, self).__init__()\n",
        "        self.encoder = EncoderBlock(d_model, d_ff, num_heads, max_seq_len)\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_seq_len)\n",
        "        self.ff_net = nn.Linear(d_model, num_classes-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_input = self.positional_encoding(self.embedding(x))\n",
        "        encoder_output = self.encoder(encoder_input)\n",
        "        aggregated_output = torch.mean(encoder_output, dim=1)\n",
        "        net_output = self.ff_net(aggregated_output)\n",
        "        return net_output\n"
      ],
      "metadata": {
        "id": "YshQsgVgUcN9"
      },
      "id": "YshQsgVgUcN9",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext.datasets import IMDB\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "def process_text(text, vocab):\n",
        "    return torch.tensor(vocab(tokenizer(text)), dtype=torch.long).to(device)\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list = [], []\n",
        "    for label, text in batch:\n",
        "        label_tensor = torch.tensor([label-1], dtype=torch.float).to(device)\n",
        "        processed_text = process_text(text, vocab)\n",
        "        label_list.append(label_tensor)\n",
        "        text_list.append(processed_text)\n",
        "    return torch.stack(label_list).to(device), pad_sequence(text_list, padding_value=vocab[\"<pad>\"], batch_first=True).to(device)\n",
        "\n",
        "def calculate_accuracy(preds, y):\n",
        "    preds = torch.sigmoid(preds)\n",
        "    rounded_preds = torch.round(preds)\n",
        "    correct = (rounded_preds == y).float()\n",
        "    accuracy = correct.sum() / len(correct)\n",
        "    return accuracy\n",
        "\n",
        "train_data = list(IMDB(split='train'))\n",
        "random.shuffle(train_data)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(data_iter for label, data_iter in train_data), specials=[\"<unk>\", \"<pad>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "# test_data = list(IMDB(split='test'))\n",
        "# random.shuffle(test_data)\n",
        "# test_loader = DataLoader(test_data, batch_size=32, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "max_seq_len = 5000\n",
        "d_ff = 2048\n",
        "learning_rate = 0.001\n",
        "num_classes = 2\n",
        "vocab_size = len(vocab)\n",
        "num_epochs = 10\n",
        "\n",
        "model = SentimentModel(d_model, d_ff, num_heads, max_seq_len, num_classes, vocab_size)\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch: {epoch + 1}\")\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    total_examples = 0\n",
        "    i = 0\n",
        "\n",
        "    model.train()\n",
        "    for labels, sequences in train_loader:\n",
        "        if i % 1000 == 0:\n",
        "          print(f\"batch {i}\")\n",
        "        i += 1\n",
        "        output = model(sequences)\n",
        "        loss = loss_fn(output, labels)\n",
        "        accuracy = calculate_accuracy(output, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_accuracy += accuracy.item()\n",
        "        total_examples += 1\n",
        "\n",
        "    print(f\"Loss in epoch {epoch + 1} is {total_loss}\")\n",
        "    print(f\"Accuracy in epoch {epoch + 1} is {total_accuracy / total_examples}\")\n"
      ],
      "metadata": {
        "id": "srjqM4K-Mheh",
        "outputId": "f11d6573-0545-431e-9ef5-b0c68a1d6834",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "srjqM4K-Mheh",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch: 1\n",
            "batch 0\n",
            "batch 1000\n",
            "batch 2000\n",
            "batch 3000\n",
            "Loss in epoch 1 is 1858.8000011891127\n",
            "Accuracy in epoch 1 is 0.67752\n",
            "Epoch: 2\n",
            "batch 0\n",
            "batch 1000\n",
            "batch 2000\n",
            "batch 3000\n",
            "Loss in epoch 2 is 1380.2212148308754\n",
            "Accuracy in epoch 2 is 0.81036\n",
            "Epoch: 3\n",
            "batch 0\n",
            "batch 1000\n",
            "batch 2000\n",
            "batch 3000\n",
            "Loss in epoch 3 is 1094.700155752711\n",
            "Accuracy in epoch 3 is 0.85792\n",
            "Epoch: 4\n",
            "batch 0\n",
            "batch 1000\n",
            "batch 2000\n",
            "batch 3000\n",
            "Loss in epoch 4 is 875.2224251364823\n",
            "Accuracy in epoch 4 is 0.89256\n",
            "Epoch: 5\n",
            "batch 0\n",
            "batch 1000\n",
            "batch 2000\n",
            "batch 3000\n",
            "Loss in epoch 5 is 694.3559186474304\n",
            "Accuracy in epoch 5 is 0.91652\n",
            "Epoch: 6\n",
            "batch 0\n",
            "batch 1000\n",
            "batch 2000\n",
            "batch 3000\n",
            "Loss in epoch 6 is 579.2364111022252\n",
            "Accuracy in epoch 6 is 0.93052\n",
            "Epoch: 7\n",
            "batch 0\n",
            "batch 1000\n",
            "batch 2000\n",
            "batch 3000\n",
            "Loss in epoch 7 is 472.01755257208424\n",
            "Accuracy in epoch 7 is 0.94616\n",
            "Epoch: 8\n",
            "batch 0\n",
            "batch 1000\n",
            "batch 2000\n",
            "batch 3000\n",
            "Loss in epoch 8 is 398.4770253817278\n",
            "Accuracy in epoch 8 is 0.95416\n",
            "Epoch: 9\n",
            "batch 0\n",
            "batch 1000\n",
            "batch 2000\n",
            "batch 3000\n",
            "Loss in epoch 9 is 395.8296305708604\n",
            "Accuracy in epoch 9 is 0.95508\n",
            "Epoch: 10\n",
            "batch 0\n",
            "batch 1000\n",
            "batch 2000\n",
            "batch 3000\n",
            "Loss in epoch 10 is 376.91443126560046\n",
            "Accuracy in epoch 10 is 0.95936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/sentiment_model_state.pth'  # Ścieżka, gdzie chcesz zapisać model\n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "UtbfwzqQklw5"
      },
      "id": "UtbfwzqQklw5",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'sentiment_model_state.pth')\n",
        "from google.colab import files\n",
        "files.download('sentiment_model_state.pth')"
      ],
      "metadata": {
        "id": "zY1EUcpHksDw",
        "outputId": "df1fefcf-dbee-476b-dbbb-6eb406061112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "id": "zY1EUcpHksDw",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a4d46e02-ba96-4def-b617-72f3e58b3ff1\", \"sentiment_model_state.pth\", 249540672)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PfZKBpyiMfsz"
      },
      "id": "PfZKBpyiMfsz"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}